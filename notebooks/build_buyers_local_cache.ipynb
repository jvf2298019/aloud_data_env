{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Construir banco de Armazenamento Local Hotmart\n",
        "\n",
        "## Configuração e Importações\n",
        "\n",
        "### Objetivo: Esse pipeline tem por objetivo normalizar os labels de pesquisa que estejam divergentes entre versões de pesquisa criados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Importações concluídas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Importações básicas\n",
        "import calendar\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "# Adiciona src ao path\n",
        "sys.path.append('../src')\n",
        "\n",
        "#\n",
        "\n",
        "# Utilitários de dados\n",
        "from data_utils import (\n",
        "    load_raw_data,\n",
        "    save_processed_data,\n",
        "    remove_duplicates,\n",
        "    handle_missing_values,\n",
        "    detect_outliers,\n",
        "    normalize_column,\n",
        "    process_phone_string,\n",
        "    process_phone_number,\n",
        "    clean_and_lower_column,\n",
        "    flatten_list_to_df\n",
        ")\n",
        "\n",
        "CRONOGRAMA_SUBDOMAIN = 'cronogramadosfluentes-xwamel'\n",
        "\n",
        "# Utilitários SQL\n",
        "from sql_utils import DatabaseConnection as Dbc, load_query_from_file\n",
        "\n",
        "# Utilitários de visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Utilitários de API\n",
        "from api_utils import (\n",
        "    make_request,\n",
        "    get_json,\n",
        "    post_json,\n",
        "    paginated_request,\n",
        "    response_to_dataframe\n",
        ")\n",
        "\n",
        "# utilitários hotmart\n",
        "from hotmart_utils import Hotmart\n",
        "\n",
        "# utilitários tmb\n",
        "from tmb_utils import TMB   \n",
        "\n",
        "# Configurações pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "# Load Database Driver\n",
        "db = Dbc()\n",
        "\n",
        "# Inicializar API Hotmart\n",
        "hotmart = Hotmart()\n",
        "\n",
        "# Inicializar API TMB\n",
        "tmb = TMB()\n",
        "\n",
        "print('✓ Importações concluídas com sucesso!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Buyers Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Hotmart Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = '../data/interim'\n",
        "HIST_FILENAME_PATTERN = 'hotmart_sales_history_{}.csv'  # por ano\n",
        "\n",
        "MODES = ['LOCAL_CACHE', 'FULL_REFRESH', 'ONLY_CURRENT_MONTH']\n",
        "MODE = MODES[0]  # altere conforme necessário\n",
        "\n",
        "def get_last_complete_month(today=None):\n",
        "    today = today or datetime.today()\n",
        "    first_of_month = today.replace(day=1)\n",
        "    last_month = first_of_month - timedelta(days=1)\n",
        "    return last_month.year, last_month.month\n",
        "\n",
        "def get_year_date_range(year, start_month=1, end_month=12):\n",
        "    start_date = f\"{year}-{start_month:02d}-01\"\n",
        "    last_day = calendar.monthrange(year, end_month)[1]\n",
        "    end_date = f\"{year}-{end_month:02d}-{last_day:02d}\"\n",
        "    return start_date, end_date\n",
        "\n",
        "def get_sales_history_period(start_date, end_date):\n",
        "    return flatten_list_to_df(hotmart.get_sales_history(start_date=start_date, end_date=end_date))\n",
        "\n",
        "START_YEAR = 2023\n",
        "today = datetime.today()\n",
        "last_year, last_month = get_last_complete_month(today)\n",
        "current_year = today.year\n",
        "current_month = today.month\n",
        "\n",
        "dfs = []\n",
        "\n",
        "if MODE == 'FULL_REFRESH':\n",
        "    # Baixa e salva dados completos de cada ano até o último mês COMPLETO\n",
        "    for year in range(START_YEAR, last_year + 1):\n",
        "        if year == last_year:\n",
        "            # Último ano pode ser incompleto (até o último mês completo)\n",
        "            start_date, end_date = get_year_date_range(year, 1, last_month)\n",
        "        else:\n",
        "            start_date, end_date = get_year_date_range(year)\n",
        "        df = get_sales_history_period(start_date, end_date)\n",
        "        dfs.append(df)\n",
        "        filename = HIST_FILENAME_PATTERN.format(year)\n",
        "        save_processed_data(df, filename, data_dir=DATA_DIR)\n",
        "elif MODE == 'LOCAL_CACHE':\n",
        "    # Lê cache anual, cria-o caso não exista (para dados completos só de até mês passado)\n",
        "    for year in range(START_YEAR, last_year + 1):\n",
        "        filename = HIST_FILENAME_PATTERN.format(year)\n",
        "        try:\n",
        "            df = load_raw_data(filename, data_dir=DATA_DIR)\n",
        "            # No caso do último ano no cache, se não está até mês passado, pega parcial e reprocessa\n",
        "            if year == last_year:\n",
        "                # Filtrar apenas até o último mês completo\n",
        "                end_date = f\"{last_year}-{last_month:02d}-{calendar.monthrange(last_year, last_month)[1]}\"\n",
        "                # A coluna de data é 'purchase_approved_date' no formato timestamp (ms)\n",
        "                df = df[\n",
        "                    pd.to_datetime(df['purchase_approved_date'], unit='ms') <= pd.to_datetime(end_date)\n",
        "                ]\n",
        "        except FileNotFoundError:\n",
        "            # Baixa ano inteiro, ou parte dele no último ano\n",
        "            if year == last_year:\n",
        "                start_date, end_date = get_year_date_range(year, 1, last_month)\n",
        "            else:\n",
        "                start_date, end_date = get_year_date_range(year)\n",
        "            df = get_sales_history_period(start_date, end_date)\n",
        "            save_processed_data(df, filename, data_dir=DATA_DIR)\n",
        "        dfs.append(df)\n",
        "else:  # ONLY_CURRENT_MONTH ou outro caso especial\n",
        "    dfs = []  # Use apenas dados do mês atual\n",
        "\n",
        "# Sempre busca dados do mês atual via API para atualiza\n",
        "current_month_start = f\"{current_year}-{current_month:02d}-01\"\n",
        "current_month_end = today.strftime(\"%Y-%m-%d\")\n",
        "df_current_month = flatten_list_to_df(\n",
        "    hotmart.get_sales_history(start_date=current_month_start, end_date=current_month_end)\n",
        ")\n",
        "dfs.append(df_current_month)\n",
        "\n",
        "df_hotmart = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "save_processed_data(df_hotmart, 'hotmart_sales_history.csv', data_dir=DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Hotmart Students\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_hotmart_students = flatten_list_to_df(hotmart.get_students(subdomain=CRONOGRAMA_SUBDOMAIN))\n",
        "\n",
        "save_processed_data(df_hotmart_students, 'hotmart_students.csv', data_dir='../data/interim')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load TMB Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_tmb = load_raw_data('tmb.csv', sep=';')\n",
        "\n",
        "\"\"\"\n",
        "Cell generated by Data Wrangler.\n",
        "\"\"\"\n",
        "def clean_data(df_tmb):\n",
        "    # Drop columns: 'Produtor', 'Pedido' and 29 other columns\n",
        "    df_tmb = df_tmb.drop(columns=['Produtor', 'Pedido', 'Endereço completo', 'Logradouro', 'Número', 'Bairro', 'Complemento', 'CEP', 'Estado', 'Cidade', 'País', 'Status', 'Status Financeiro', 'Status Cancelamento', 'Ticket (R$)', 'Modalidade de Contrato', 'Criado Em', 'Data Efetivado', 'Data Cancelado', 'utm_source', 'utm_medium', 'utm_campaign', 'utm_content', 'utm_last_source', 'utm_last_medium', 'utm_last_campaign', 'utm_last_content', 'Renovação automatica', 'Data de Renovação Prevista', 'Renovação enviada', 'Oferta'])\n",
        "    # Drop column: 'Cliente CPF'\n",
        "    df_tmb = df_tmb.drop(columns=['Cliente CPF'])\n",
        "    # Rename column 'Produto' to 'offer_code'\n",
        "    df_tmb = df_tmb.rename(columns={'Produto': 'offer_id', \"Cliente Nome\": \"name\", \"Cliente Email\": \"email\", \"Telefone\": \"phone\"})\n",
        "\n",
        "    df_tmb['phone'] = process_phone_string(df_tmb, 'phone')\n",
        "    \n",
        "    return df_tmb\n",
        "\n",
        "df_tmb = clean_data(df_tmb.copy())\n",
        "\n",
        "save_processed_data(df_tmb, 'tmb_buyers_data.csv', data_dir='../data/interim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "TMB_HIST_FILENAME_PATTERN = 'tmb_pedidos_history_{}.csv'\n",
        "\n",
        "dfs_tmb = []\n",
        "\n",
        "if MODE == 'FULL_REFRESH':\n",
        "    # Baixa e salva dados completos de cada ano até o último mês completo\n",
        "    for year in range(START_YEAR, last_year + 1):\n",
        "        if year == last_year:\n",
        "            # Último ano: até o último mês completo\n",
        "            start_date, end_date = get_year_date_range(year, 1, last_month)\n",
        "        else:\n",
        "            start_date, end_date = get_year_date_range(year)\n",
        "        df = pd.DataFrame(tmb.get_pedidos(data_inicio=start_date, data_final=end_date, page_size=100))\n",
        "        dfs_tmb.append(df)\n",
        "        filename = TMB_HIST_FILENAME_PATTERN.format(year)\n",
        "        save_processed_data(df, filename, data_dir=DATA_DIR)\n",
        "elif MODE == 'LOCAL_CACHE':\n",
        "    for year in range(START_YEAR, last_year + 1):\n",
        "        filename = TMB_HIST_FILENAME_PATTERN.format(year)\n",
        "        try:\n",
        "            df = load_raw_data(filename, data_dir=DATA_DIR)\n",
        "            # No caso do último ano, garante filtro apenas até o último mês completo\n",
        "            if year == last_year and 'criado_em' in df.columns and not df.empty:\n",
        "                end_date = f\"{last_year}-{last_month:02d}-{calendar.monthrange(last_year, last_month)[1]}\"\n",
        "                # Conversão explícita de timezone para evitar TypeError\n",
        "                # 1. Garante que 'criado_em' é datetime com no timezone.\n",
        "                # 2. Remove timezone antes da comparação\n",
        "                criado_em_dt = pd.to_datetime(df['criado_em'], errors='coerce').dt.tz_localize(None)\n",
        "                end_date_dt = pd.to_datetime(end_date)\n",
        "                df = df[criado_em_dt <= end_date_dt]\n",
        "        except FileNotFoundError:\n",
        "            if year == last_year:\n",
        "                start_date, end_date = get_year_date_range(year, 1, last_month)\n",
        "            else:\n",
        "                start_date, end_date = get_year_date_range(year)\n",
        "            df = pd.DataFrame(tmb.get_pedidos(data_inicio=start_date, data_final=end_date, page_size=100))\n",
        "            save_processed_data(df, filename, data_dir=DATA_DIR)\n",
        "        dfs_tmb.append(df)\n",
        "else:  # ONLY_CURRENT_MONTH ou qualquer outro modo: só mês atual\n",
        "    dfs_tmb = []\n",
        "\n",
        "# Sempre busca o mês atual via API para atualizar (se não for só current month, concatena aos anteriores)\n",
        "current_month_start = f\"{current_year}-{current_month:02d}-01\"\n",
        "current_month_end = today.strftime(\"%Y-%m-%d\")\n",
        "df_tmb_current_month = pd.DataFrame(\n",
        "    tmb.get_pedidos(data_inicio=current_month_start, data_final=current_month_end, page_size=100)\n",
        ")\n",
        "dfs_tmb.append(df_tmb_current_month)\n",
        "\n",
        "# Concatena tudo e salva dataset total; garante coluna de data criada_em existe\n",
        "df_tmb_api = pd.concat(dfs_tmb, ignore_index=True)\n",
        "if 'criado_em' not in df_tmb_api.columns:\n",
        "    df_tmb_api['criado_em'] = pd.NaT  # placeholder caso não venha nenhum dado\n",
        "\n",
        "save_processed_data(df_tmb_api, 'tmb_pedidos_data.csv', data_dir=DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Generic Buyers Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_generic_buyers = db.execute_query_from_file(\n",
        "    'select_generic_sales',\n",
        "    params={\"product_name\": \"Cronograma dos Fluentes\"}\n",
        ")\n",
        "\n",
        "df_generic_buyers['phone'] = df_generic_buyers['phone'].apply(lambda x: str(int(x)) if isinstance(x, float) else x)\n",
        "\n",
        "df_generic_buyers['phone'] = process_phone_string(df_generic_buyers, 'phone')\n",
        "\n",
        "save_processed_data(df_generic_buyers, 'generic_buyers_data.csv', data_dir='../data/interim')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
